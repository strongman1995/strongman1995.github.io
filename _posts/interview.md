# 网上收集的面试经历

# 腾讯

面试内容偏研究

CRF as RNN? 

训练数据量远少于语义分割

如何训练

如何防止过拟合

是否用到 pretrained model

常规的数据增强，有哪几种

Adversarial Training 



对于某一大类方法的研究脉络与发展历程

每个算法的 motivation 到 formulation

求解优化的细节，算法的本质，不同方法之间的比较

希望可以按照一篇学术论文的思路，将整个项目的历程

- background & motivation：和别人 paper 方法的差别
- Related works：
- Our approach：
- Conclusion & Future works：

### CV

详细介绍深度学习网络结构的发展历程，从lenet5->AlexNet到VGG再到ResNet再到DenseNet => 延伸问题：为什么DenseNet效果可以比ResNet更好

LeNet 1998

AlexNet 2012

ZF Net 2013

VGG Net 2014

GoogLeNet 2014

Microsoft resNet 2015

DenseNet 2016

Faster R-CNN 2015

GAN 2014 cycle GAN

ResNet 2015

pix2pix

### DL

1. 介绍深度学习优化方法的研究脉络与发展历程，从SGD到Momentum再到Adagrad和RMSProp，最后详细讲Adam

2. 解决Overfitting、regulation的方法：regulation，我才总结下了，大致主要聊了2点：

   1）dropout,介绍dropout的概念啊，问了下train和test阶段的不一样过程细节

   主要讲了下test把active function的输出都乘以P，这样就把train和test的输出期望都scale到了一个range，这样才是更加准确的

   2）Batch Normalisation:BN，BN的原理，问什么好，好在哪里？

   1.降低了样本之间的差异，scale到（0，1）

   2，降低了层层之间的依赖，主要体现在前一层的输出是下一层的输入，那么我们把所有数据都scale到了（0，1）的distribution，那么降低了层层之间的依赖关系，从而使数据更加准确

3. 你知道感知野吗？什么作用？你知道卷积的作用吗？你用过池化层吗？有哪些？

   当时一脸懵逼，感知野是神马啊？最后再次确认了感知野其实就是在多个kernel做卷积的时候的窗口区域，就是3个33等于1个77的感知大小。

   卷积的作用是提取特征，前面的卷积提取类似于人眼能识别的初步特征，后面的卷积是能够提取更加不容易发现但是真实存在的特征。

   Pooling 用过，max pooling， average pooling， global average pooling。再问这个两个分别有什么用？

   max pooling我蠢到说提取最有特征的特征，其实就是最具有代表性的特征；average pooling提取的是比较general 的特征；global average pooling用来分类的，因为后面网络的加深，full connected layer参数太多了，不容易训练，为了快速准确得到结果，采用global average pooling，没有参数，但是得到的分类效果跟FC差不多。

4. 对于提供可以自由裁剪pre-train model，怎么保证你输出的前面部分的check point 参数与模型结构 freeze在一起能在新的任务里，表现好？有没有实验数据支撑？
5. 你知道depthwise-CNN吗？讲讲具体原理？那1*1的kernel的作用是什么呢？对网络model有什么影响？
6. 你还知道或者学习过那些传统机器学习算法？XGBoost？HMM？SVM等等都清楚吗？

### statistic ML

**总结：**对每个算法，尽量能够做到可以手推其损失函数、清晰讲解如何求解损失函数，同时，了解该算法的应用场景和优缺点。并将应用场景类似的算法进行比较。还有一点需要注意的是，针对每个问题，要尽可能了解的深入，例如，L1，L2 正则化，除了以上的问题，还有 L1，L2 的先验分布是什么，正则化的参数选择问题等等。

1. 了解传统机器学习吗 => 了解 => 那你来讲讲SVM吧 => balabala => 如何解决线性不可分问题 => balabala

2. SVM和Logistic Regression对比：首先我介绍了下logistics regression的过程，就是把y=wx+b的结果放到sigmoid函数里，把sigmoid作为一个分类器，这样做的原因是sigmoid函数能把所有范围的值域控制在（0，1）区间内，然后我们把0.5作为一个分类的阈值，大于0.5的作为正类，小于0.5的作为负类。然后SVM是一个利用超平面将数据隔开分类的问题，首先我们在max所有距离平面最近的点的margin，同时subject to y(wx+b)>0,意味着分类正确：

   然后：我们可以的到最近点到平面的距离：

   我们最后再用拉格朗日乘子式将subjuct to 条件转换成一个等式求解最后的w,b 然后求得最有超平面。我说SVM有很多kernel，这个有点像regulation，面试官说错了，你讲讲kernel是什么干什么用的？我说kernel是把数据把低维映射到高维，因为有些数据在低维不可分，映射高维可以找到超平面去划分，更好准确。

   最后说了LR比较方便计算，SVM 高维kernel计算复杂，但是准确。如果数据多，要求实时得到预测结果，用LR；如果数据不多，要求准确率，我选择SVM。另外SVM可以用于多分类，而LR只能用于二分类

3. L1 L2 正则化的区别，为什么 L1 产生稀疏矩阵，L2 可以防止过拟合 (0.5)；

4. 梯度消失和梯度爆炸 (0.4)；

5. LR 的数学原理 (0.4)；

6. SVM 推导 (0.35)；

7. SVM 核函数 (0.35)；

8. 算法评估指标 ROC曲线，AUC值 (0.3)；

9. bagging 和 boosting 区别 (0.3)；

10. RF、AdaBoost、GBDT、XGBoost 的区别和联系 (0.3)。



### RL

- 详细问了有关RL的一系列问题，分value-based方法和policy-based方法

- - policy-based方法和value-based主要的区别在于哪里 => 从Bellman equation开始各种胡扯

  - value-based方法学习的目标是什么

  - 讲policy-based方法的研究脉络与发展历程 => 从policy gradient theorem讲到REINFORCE，从DDPG讲到A2C，从TRPO讲到PPO

  - - 追问一：value function在TRPO中的作用是什么
    - 追问二：带value function的模型在优化时如何迭代
    - 追问三：value function的loss可不可以和policy的loss放到同一个框架下
    - 追问四：介绍PPO => 两种objective function

### hashmap

python中dictionary也是用hash表实现的：首先利用hash()将key和value映射到一个地址，它通过把key和value映射到表中一个位置来访问记录，这种查询速度非常快，更新也快。而这个映射函数叫做哈希函数，存放值的数组叫做哈希表。 哈希函数的实现方式决定了哈希表的搜索效率。具体操作过程是：

**数据添加**：把key通过哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里。

**数据查询**：再次使用哈希函数将key转换为对应的数组下标，并定位到数组的位置获取value。

但是，对key进行hash的时候，不同的key可能hash出来的结果是一样的，尤其是数据量增多的时候，这个问题叫做**哈希冲突**。

如果解决这种冲突情况呢？通常的做法有两种，一种是链接法，另一种是开放寻址法，Python选择后者。

**开放寻址法（open addressing）**：

开放寻址法中，所有的元素都存放在散列表里，当产生哈希冲突时，通过一个探测函数计算出下一个候选位置，如果下一个获选位置还是有冲突，那么不断通过探测函数往下找，直到找个一个空槽来存放待插入元素。



### **概率题**

面试中考到的问题中，几乎 80% 的问题都是条件概率题，贝叶斯公式一定要牢记于心。因此，大家在准备的过程中，需要重点准备条件概率问题。下面是面经中出现频率最高的面试题，希望给大家的面试准备上提供一点线索。

**一、随机数发生器** 这类题目在解决的过程中要注意：最后产生的随机数中，可以存在没有用的随机数，但必须保证所有要用到的随机数产生的概率必须是相同的。

> 已知一随机发生器，产生 0 的概率是 p，产生 1 的概率是 1-p，现在要你构造一个发生器，使得它产生 0 和 1 的概率均为 1/2。

**求解：**让该随机数生成器生成两个数，那么序列是 00，01，10，11 概率分别为 pp，p(1-p)，(1-p)p，(1-p)(1-p)。我们发现产生序列 01 以及 10 的概率是相等的，那么我们把 01 看作为 0，把 10 看作是 1，则他们产生的概论均为 p(1-p)，其他情况舍弃不用，这样就得到了0和 1 均等生成的随机器了。

> 已知有个 rand7() 的函数，返回 1 到 7 随机自然数，怎样利用这个 rand7() 构造 rand10()，随机产生出 1 到 10 的自然数。

**求解：**如果能够得到一组等概率的数，不管是什么数，只要等概率而且个数大于 10，那么问题就可以解决了。事实上，解决方案是有无数种的，只要保证产生的结果映射到 1 到 10 的自然数后，是等概率的独立事件即可。例如， (rand7() - 1) * 7 + rand7()，可以等概率的生成 1 到 49，那么，只要把 11-49 去掉就可以了。不过这样的做法在实际使用过程中毕竟低效。因此可以去掉 41-49，然后在把 1-40 映射到 1-10 （每四个数映射为 1 个数），那么问题也就解决了。

**二、掷筛子的期望** 商家发明一种扔筛子游戏，顾客扔到多少点就得到多少钱，但扔筛子之前顾客需要付一定数量的钱 x，假设商家和顾客都足够聪明：

1. 顾客付一次钱可以扔一次的情况下，顾客能接受的最大 x 是多少？
2. 现在规则改为顾客付一次钱可以扔两次，顾客扔了第一次之后可以选择是否继续扔第二次，如果扔了第二次则以第二次的结果为准，如果没有扔第二次就以第一次的结果为准，这时顾客能接受的最大 x 为多少？

**求解：**题目本质上是问掷一次筛子的期望以及掷两次筛子的期望。 

1. 1/6 (1 + 2 + 3 + 4 + 5 + 6) = 3.5。
2. 考虑顾客什么情况下会扔第二次，就是扔第二次得到钱变多的概率相对较大的时候，那么当顾客第一次扔到 1，2，3 的时候他会选择继续扔第二次，则这时候期望变为 1/6 (4+5+6) + 1/2 (1/6 (1+2+3+4+5+6)) = 4.25。

### 项目

介绍机器学习项目的时候，项目中的损失函数、如何优化、怎么训练模型的、用的什么数据集能够十分清晰的描述出来。对自己做过的项目要自信一些，在讲解的过程中不要自己有一些疑惑或者模棱两可的说法。以下是几个在介绍自己项目时需要注意的点。

**准备细节：**一旦被问倒了，面试官在心里就认为你没做过。在面试前，应当适当的准备项目描述的一些说辞。很多同学在准备的过程中，会局限于项目具体完成了哪些业务，以及代码实现中的各种细节。事实上，这并不是一个非常好的回答，这相当于把后继提问权直接交给面试官，很可能在中间环节被面试官直接打断，提问中间他感兴趣的某些细节。

因此，建议大家按照以下的方式进行介绍：

1. 讲述项目的基本情况，项目的背景、规模、用时、用到的技术以及各个模块。重点突出自己比较熟悉的技术，防止在面试官打断的提问的时候，问到自己最薄弱的环节。
2. 主动说出自己做了哪些事情，这部分的描述要尽量和自己的技术背景一致，描述自己在项目中的角色。
3. 描述模块中用到的技术细节，这部分一定要注意，一定要把话题到自己最熟悉模块的技术细节。自己说出口的技术，一定要是自己会的，宁可少说，不要夸大。
4. 注意面试官提问的问题，不要太过于简单的回答，尽量把自己知道的相关的部分都说出来。
5. 注意不要说得太流利，让面试官感觉自己是在背答案。要一遍思考一遍说。

展现自己在技术和项目上的思考，表现自己的工程能力，下面列出几点：

1. 能考虑到代码的扩展性，有框架设计的意识；
2. 有调优意识，能通过监控发现问题点，然后解决；
3. 动手能力很强，肯干活，会的东西比较多，团队合作精神比较好；
4. 有主见，能不断探索新的知识。

**一定要主动：**作为面试者，应该能够主动并且逻辑清晰的说出自己的项目中有哪些亮点，能够主动的把自己的闪光点在短短几十分钟的面试中都展现出来

# 面试编程题

**总结：**《剑指 offer》基本是要过一遍的，面试中有很多同学指出很多是来自这本书的原题。另外，总结题目类型以及对应的解题方法也是很有必要的，题目场景多种多样，但其本质的问题总的来说只有那么几种。如果有余力，可以多多练习 LeetCode。建议大家刷题的时候，最好用 Java 或者 C++，很多面试官不太喜欢大家做题的时候使用 Python。

1. 数组中的逆序对。 Lintcode原题：https://www.lintcode.com/zh-cn/problem/reverse-pairs/ 
2.  二叉查找树 给定一个前置条件，将二叉树中满足条件的二叉树节点进行删除。先要求描述思路，再进行算法编写。 Lintcode类似题：http://www.lintcode.com/zh-cn/problem/remove-node-in-binary-search-tree/ 

3. 一道考察递归的相关算法。 Lintcode原题-二叉树的最大深度：http://www.lintcode.com/zh-cn/problem/maximum-depth-of-binary-tree/ 
4. 给定一个无向边的列表，判断其是否为树结构。 Lintcode原题： http://www.lintcode.com/zh-cn/problem/graph-valid-tree/ 
5. 两个数组取交集，讲算法，推复杂度
6. 快排的时间复杂度和空间复杂度？平均多少？最差多少？还有那些排序的时间复杂度是O(nlogn)? 知道排序中的稳定性吗？我：快排的时间复杂度我记很清楚是O(nlogn),空间复杂度是O(1)，平均就是O(nlogn)，最差是O(n^2),退化成了冒泡排序；此外还有时间复杂度为O（nlogn）的还有堆排序和归并排序；排序的稳定性知道是在排序之前，有两个元素A1,A2,A1在A2之前，在排序之后还是A1在A2之前。
7. 不用math中的取平法差，判断一个自然数是不是可以开方（时间复杂度尽量低）？
8. 快排 (0.4)
9. 归并排序 (0.3)
10. 10 万个数中找 TopK(0.3)
11. 最长回文子串 (0.2)
12. 反序字符串 (0.2)
13. 链表反转 (0.2)